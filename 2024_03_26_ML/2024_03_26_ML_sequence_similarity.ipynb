{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 09:29:09 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   48C    P8    21W / 240W |    710MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2023      G   /usr/lib/xorg/Xorg                386MiB |\n",
      "|    0   N/A  N/A      2198      G   /usr/bin/gnome-shell               89MiB |\n",
      "|    0   N/A  N/A      3928      G   ...6/usr/lib/firefox/firefox      231MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_per_process_memory_fraction(0.2, 0)\n",
    "torch.cuda.is_available()\n",
    "#device = torch.device(\"cuda:0\")\n",
    "torch.set_num_threads(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 09:29:10 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   49C    P2    27W / 240W |    866MiB /  8192MiB |     55%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2023      G   /usr/lib/xorg/Xorg                386MiB |\n",
      "|    0   N/A  N/A      2198      G   /usr/bin/gnome-shell               89MiB |\n",
      "|    0   N/A  N/A      3928      G   ...6/usr/lib/firefox/firefox      231MiB |\n",
      "|    0   N/A  N/A     13897      C   ...sm_coding_club/bin/python      154MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Human_ACE_orthologues.fa\") as file:\n",
    "    fasta_seqs = list(SeqIO.parse(file, \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(i.id, str(i.seq)) for i in fasta_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ENSOGAP00000006131_Bushbaby',\n",
       "  'MGASSGLRASGPPPVLSLLPLLQLLLLPPSPAAQALDPGLLPGNFSADEAGAQLFAQSYNSSAEQVLFQSTAASWAYSTNITEENAQRQEEAVLLNQRFAEAWGQKAKELYGPIWQNFTDPKLRKVIRAVCTLGPANLPLAKQQQYVSLQTNMSRIYSTTKVCFPNKTATCWSLDPELTNILASSRSYARLLFAWEGWHDTVGIPLKALYQDFTTISNEAYRQDGFSDTGAYWRSWYNSATFEEDLEHLYHQLEPLYLNLHAYVRRALHRRYGDRYINLRGPIPAHLLGDMWAQSWDNLYDMVVPFPGKPNLDVTSTMVKQGWNATHMFRVAEEFFTSLGLSPMPPEFWAESMLEKPADGREVVCHASAWDFYNRKDFRIKQCTQVTMDQLSTVHHEMGHVQYYLQYKDQPVSLREGANPGFHEAIGDVLGLSVSTPAHLHKIGLLDHVTNDTESDINYLLKMALDKIAFLPFGYLVDQWRWGVFSGHTPPSRYNSDWWYLRTKYQGICPPVVRNETHFDAGAKFHIPNGTPYIRYFVSFILQFQFHQALCKEAGHQGPLHQCDIYKSTQAGAKLQEVLRAGSSRPWQEVLKNMTGSDALDAQPLLDYFQPVSQWLQEQNQQNNEILGWPEYQWRPPLPTNYPEGIDLITDEAEANKFVEEYDQVSQVVWNEFAEANWNYNTNITTEASQILLQKNLEIANHTLKWGIQARQFDVSTFQNTTTKRVIKKVQDLDRAALPAKELEEYNKILLEMETTYSVATVCHTNGTCLQLEPDLTSMMATSRQYYELLWAWKSWRDKVGRAILPSFPKYVELTNKAARLNGYIDGGDSWRSMYEMPSLEQNLEELFQELQPLYLNLHAYVRRALHRHYGAQHINLEGPIPAHLLGNMWAQTWSNIYDLVVPFPSAPSMDATEAMIKQGWTPRRMFKEADNFFISLGLLPVPPEFWNKSMLEKPTDGREVVCHASAWDFYNGKDFRIKQCTSVNMEDLVVAHHEMGHIQYFMQYKDLPVALREGANPGFHEAIGDVLALSVSTPKHLHSLNLLSSEGVGYENDINFLMKMALDKVAFIPFSYLVDQWRWRVFDGSISKENYNQEWWSLRLKYQGLCPPVARSQGDFDPGAKFHIPSSVPYIRYFVSFVIQFQFHEALCHAAGHEGPLHKCDIYQSKEAGKRLADAMKLGFSKPWPEAMKLITGQPNMSASAMMNYFKPLLDWLVTENGRHGEKLGWPQYNWTPDSARSEGPVPDTGRVNFLGLNLDAQQARVGQWVLLFLGVALLVATLGLTQRLFSIRHHSIRRPHRGPQFGSEVELRHS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "#model = model.to(device)\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "#data = [\n",
    "#    (\"protein1\", \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"),\n",
    "#    (\"protein2\", \"KALTARQQEVFDLIRDHISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"),\n",
    "#    (\"protein2 with mask\",\"KALTARQQEVFDLIRD<mask>ISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"),\n",
    "#    (\"protein3\",  \"K A <mask> I S Q\"),\n",
    "#]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "#batch_tokens = batch_tokens.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision.models as models\n",
    "#from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with profile(activities=[ProfilerActivity.CPU],\n",
    "#        profile_memory=True, record_shapes=True) as prof:\n",
    "#    model(batch_tokens)\n",
    "\n",
    "#print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 23 09:29:17 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   49C    P2    56W / 240W |    864MiB /  8192MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2023      G   /usr/lib/xorg/Xorg                386MiB |\n",
      "|    0   N/A  N/A      2198      G   /usr/bin/gnome-shell               89MiB |\n",
      "|    0   N/A  N/A      3928      G   ...6/usr/lib/firefox/firefox      231MiB |\n",
      "|    0   N/A  N/A     13897      C   ...sm_coding_club/bin/python      152MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "\n",
    "# Look at the unsupervised self-attention map contact predictions\n",
    "import matplotlib.pyplot as plt\n",
    "for (_, seq), tokens_len, attention_contacts in zip(data, batch_lens, results[\"contacts\"]):\n",
    "    plt.matshow(attention_contacts[: tokens_len, : tokens_len])\n",
    "    plt.title(seq)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "esm_coding_club"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
